Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,0.43251956,5.562335958005249,0.9335078,0.968290659661074,0.968290659661074,0.011422452,0.23718257,0.0002969681,1.0
20000,0.1246126,4.802204176334107,0.9733951,0.994667445147397,0.994667445147397,3.0962994e-05,0.24224834,0.0002910184,1.0
30000,0.16719913,4.8010440835266825,0.9735745,0.9946635781750601,0.9946635781750601,6.245591e-05,0.24748532,0.00028500403,1.0
40000,0.12673359,4.811046511627907,0.9721803,0.9940755864789407,0.9940755864789407,0.00047496517,0.23904161,0.00027899066,1.0
50000,0.096391924,4.827505827505828,0.9728085,0.9928904479762457,0.9928904479762457,0.001169057,0.2371598,0.00027300528,1.0
60000,0.08998766,4.800464037122969,0.9734084,0.994667445147397,0.994667445147397,1.5093213e-05,0.24207534,0.00026702438,1.0
70000,0.07179449,4.8,0.9730988,0.9946666717529297,0.9946666717529297,2.7062482e-05,0.23653351,0.00026101095,1.0
80000,0.047679927,4.802089378990133,0.973401,0.9946604810062702,0.9946604810062702,2.6106403e-05,0.24796622,0.000255001,1.0
90000,0.035451178,4.799883990719257,0.9729878,0.994667445147397,0.994667445147397,2.4067404e-05,0.23760277,0.00024898862,1.0
100000,0.069376156,4.8010440835266825,0.9734595,0.9946635781750601,0.9946635781750601,2.5779364e-05,0.24501199,0.00024297701,1.0
110000,0.15803757,4.8010440835266825,0.9734794,0.9946655116612286,0.9946655116612286,2.6218911e-05,0.23505592,0.00023699478,1.0
120000,0.1709168,4.802089378990133,0.9730758,0.9946643502229324,0.9946643502229324,1.8346465e-05,0.23962808,0.00023101202,1.0
130000,0.16971755,4.801624129930395,0.97355944,0.9946635781750601,0.9946635781750601,1.8029888e-05,0.23981328,0.00022500171,1.0
140000,0.17741503,4.810575246949448,0.9721754,0.9940790289050787,0.9940790289050787,0.0005002699,0.23897912,0.00021898816,1.0
